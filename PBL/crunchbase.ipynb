{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. pip install selenium\n",
    "2. <https://sites.google.com/a/chromium.org/chromedriver/downloads>에서 자기 크롬 버전에 맞는 실행파일 다운"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "import winsound\n",
    "from winsound import Beep\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path=\"D:\\\\Users\\\\Download\\\\기계학습및딥러닝응용연구\\\\논문\\\\webScrapping\\\\chromedriver.exe\")\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.crunchbase.com\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login\n",
    "\n",
    "ID = \"-\"\n",
    "PW = \"-\"\n",
    "\n",
    "driver.find_element_by_xpath(\"/html/body/chrome/div/app-header/div[1]/div[2]/div/anon-nav-row/nav-action-item[2]/nav-header-action-item/a/span[1]/nav-action-item-header-layout/div/span\").click()\n",
    "time.sleep(0.5)\n",
    "\n",
    "driver.find_element_by_xpath(\"/html/body/chrome/div/mat-sidenav-container/mat-sidenav-content/div/authentication-page/page-layout/div/div/authentication/mat-card/mat-tab-group/div/mat-tab-body[1]/div/login/form/mat-form-field[1]/div/div[1]/div/input\").send_keys(ID)\n",
    "time.sleep(0.5)\n",
    "\n",
    "driver.find_element_by_xpath(\"/html/body/chrome/div/mat-sidenav-container/mat-sidenav-content/div/authentication-page/page-layout/div/div/authentication/mat-card/mat-tab-group/div/mat-tab-body[1]/div/login/form/mat-form-field[2]/div/div[1]/div/input\").send_keys(PW)\n",
    "time.sleep(0.5)\n",
    "\n",
    "driver.find_element_by_xpath(\"/html/body/chrome/div/mat-sidenav-container/mat-sidenav-content/div/authentication-page/page-layout/div/div/authentication/mat-card/mat-tab-group/div/mat-tab-body[1]/div/login/form/button/span[1]\").click()\n",
    "time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "detail_xpath = \"/html/body/chrome/div/mat-sidenav-container/mat-sidenav-content/div/list-search/page-layout/div/div/form/div/results/div/div/div[3]/sheet-grid/div/div/grid-body/div/grid-row[%s]/grid-cell[2]/div/field-formatter/identifier-formatter/a/div/div\"\n",
    "\n",
    "read_more = \"/html/body/chrome/div/mat-sidenav-container/mat-sidenav-content/div/ng-component/entity-v2/page-layout/div/div/div/page-centered-layout[3]/div/div/div[1]/row-card[1]/profile-section/section-card/mat-card/div[2]/div/description-card/button/span[1]/label-with-icon/span\"\n",
    "\n",
    "next_button = \"/html/body/chrome/div/mat-sidenav-container/mat-sidenav-content/div/list-search/page-layout/div/div/form/div[2]/results/div/div/div[1]/div/results-info/h3/a[2]/span[1]/div/span\"\n",
    "\n",
    "mouse_move = \"/html/body/chrome/div/mat-sidenav-container/mat-sidenav-content/div/list-search/page-layout/div/div/header/h1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNum=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "descriptions = []\n",
    "industries = []\n",
    "page = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#메모리 날라갔을때 합치는 코드\n",
    "# df1 = pd.read_csv('business_description_20201204_14.csv')\n",
    "# for i in range(0,len(df1)):\n",
    "#     names.append(df1['company'].iloc[i])\n",
    "#     descriptions.append(df1['description'].iloc[i])\n",
    "#     industries.append(df1['industries'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_url = \"https://www.crunchbase.com/lists/dd/31cbd690-d6f1-44e7-9ecb-9180c53e4c0d/organizations\"\n",
    "driver.get(companies_url)\n",
    "time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실행이 멈췄던 숫자를 입력하세요, 처음이라면 1 입력: 16\n",
      "error occured\n"
     ]
    }
   ],
   "source": [
    "k = int(input(\"실행이 멈췄던 숫자를 입력하세요, 처음이라면 1 입력: \"))\n",
    "a=1.5 \n",
    "b=1.9\n",
    "try:\n",
    "    for i in range(k, 51):\n",
    "            sleepTime = round(random.uniform(a, b), 2)\n",
    "            driver.find_element_by_xpath(detail_xpath % str(i)).click()\n",
    "            time.sleep(sleepTime+2)\n",
    "            try:\n",
    "                driver.find_element_by_xpath(read_more).click()\n",
    "                time.sleep(sleepTime+0.5)\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, \"lxml\",from_encoding='utf-8')\n",
    "\n",
    "                name = soup.find_all(\"span\", attrs={\"class\": \"profile-name\"})[0].text\n",
    "                \n",
    "                \n",
    "                # About\n",
    "                description = soup.find_all(\"span\", attrs={\"class\": \"description\"})[0].text\n",
    "                description += '\\n\\n'                        \n",
    "                \n",
    "                #description1                                \n",
    "                descriptNum = len(soup.find(\"span\", {\"class\":\"has-overflow\"}).find_all(\"p\"))\n",
    "                \n",
    "                for j in range(0, descriptNum):\n",
    "                    if(j!=0):\n",
    "                        description += '\\n\\n'\n",
    "                    description += soup.find(\"span\", {\"class\":\"has-overflow\"}).find_all(\"p\")[j].text\n",
    "                                                                  \n",
    "                description += ' '\n",
    "                \n",
    "                #description2  \n",
    "                descriptNum = len(soup.find(\"span\", {\"class\":\"overflow-description\"}).find_all(\"p\"))\n",
    "\n",
    "                for j in range(0, descriptNum):\n",
    "                    if(j!=0):\n",
    "                        description += '\\n\\n'\n",
    "                    description += soup.find(\"span\", {\"class\":\"overflow-description\"}).find_all(\"p\")[j].text         \n",
    "                \n",
    "                \n",
    "                \n",
    "                #industry\n",
    "                classNum = len(soup.find_all(\"mat-chip\", attrs={\"class\": \"mat-chip\"}))\n",
    "                industry = \"\"\n",
    "                for j in range(0, classNum):\n",
    "                    if(j!=0):\n",
    "                        industry += ', '\n",
    "                    industry += soup.find_all(\"mat-chip\", attrs={\"class\": \"mat-chip\"})[j].text\n",
    "                \n",
    "            except:\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, \"lxml\",from_encoding='utf-8')\n",
    "\n",
    "                name = soup.find_all(\"span\", attrs={\"class\": \"profile-name\"})[0].text               \n",
    "\n",
    "                \n",
    "                #description\n",
    "                descriptNum = len(soup.find_all(\"span\", attrs={\"class\": \"description\"}))\n",
    "                description = \"\"\n",
    "                for j in range(0, descriptNum):\n",
    "                    if(j!=0):\n",
    "                        description += '\\n\\n'\n",
    "                    description += soup.find_all(\"span\", attrs={\"class\": \"description\"})[j].text\n",
    "                    \n",
    "                    \n",
    "                #industry                \n",
    "                classNum = len(soup.find_all(\"mat-chip\", attrs={\"class\": \"mat-chip\"}))\n",
    "                industry = \"\"\n",
    "                for j in range(0, classNum):\n",
    "                    if(j!=0):\n",
    "                        industry += ', '\n",
    "                    industry += soup.find_all(\"mat-chip\", attrs={\"class\": \"mat-chip\"})[j].text\n",
    "                    \n",
    "\n",
    "            names.append(name)\n",
    "            descriptions.append(description)            \n",
    "            industries.append(industry)\n",
    "\n",
    "            print(\"Page Number: %d\\ni: %d\\nCompany Name: %s\\n\" % (page, i, name))\n",
    "\n",
    "            driver.back()\n",
    "            time.sleep(sleepTime)\n",
    "            driver.find_element_by_xpath(mouse_move).click()\n",
    "            time.sleep(sleepTime)\n",
    "            \n",
    "    print(\"next\")    \n",
    "    driver.find_element_by_xpath(next_button).click()            \n",
    "    time.sleep(6)\n",
    "    page += 1\n",
    "            \n",
    "    while True:\n",
    "        stopNum =1\n",
    "        for i in range(1, 51):\n",
    "            sleepTime = round(random.uniform(a, b), 2)\n",
    "            stopNum += 1\n",
    "            driver.find_element_by_xpath(detail_xpath % str(i)).click()\n",
    "            time.sleep(sleepTime+2)\n",
    "            try:\n",
    "                driver.find_element_by_xpath(read_more).click()\n",
    "                time.sleep(sleepTime+0.5)\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, \"lxml\",from_encoding='utf-8')\n",
    "\n",
    "                name = soup.find_all(\"span\", attrs={\"class\": \"profile-name\"})[0].text\n",
    "                \n",
    "                \n",
    "                # About\n",
    "                description = soup.find_all(\"span\", attrs={\"class\": \"description\"})[0].text\n",
    "                description += '\\n\\n'                        \n",
    "                \n",
    "                #description1                                \n",
    "                descriptNum = len(soup.find(\"span\", {\"class\":\"has-overflow\"}).find_all(\"p\"))\n",
    "                \n",
    "                for j in range(0, descriptNum):\n",
    "                    if(j!=0):\n",
    "                        description += '\\n\\n'\n",
    "                    description += soup.find(\"span\", {\"class\":\"has-overflow\"}).find_all(\"p\")[j].text\n",
    "                                                                  \n",
    "                description += ' '\n",
    "                \n",
    "                #description2  \n",
    "                descriptNum = len(soup.find(\"span\", {\"class\":\"overflow-description\"}).find_all(\"p\"))\n",
    "\n",
    "                for j in range(0, descriptNum):\n",
    "                    if(j!=0):\n",
    "                        description += '\\n\\n'\n",
    "                    description += soup.find(\"span\", {\"class\":\"overflow-description\"}).find_all(\"p\")[j].text         \n",
    "                \n",
    "                \n",
    "                \n",
    "                #industry\n",
    "                classNum = len(soup.find_all(\"mat-chip\", attrs={\"class\": \"mat-chip\"}))\n",
    "                industry = \"\"\n",
    "                for j in range(0, classNum):\n",
    "                    if(j!=0):\n",
    "                        industry += ', '\n",
    "                    industry += soup.find_all(\"mat-chip\", attrs={\"class\": \"mat-chip\"})[j].text\n",
    "                \n",
    "            except:\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, \"lxml\",from_encoding='utf-8')\n",
    "\n",
    "                name = soup.find_all(\"span\", attrs={\"class\": \"profile-name\"})[0].text               \n",
    "\n",
    "                \n",
    "                #description\n",
    "                descriptNum = len(soup.find_all(\"span\", attrs={\"class\": \"description\"}))\n",
    "                description = \"\"\n",
    "                for j in range(0, descriptNum):\n",
    "                    if(j!=0):\n",
    "                        description += '\\n\\n'\n",
    "                    description += soup.find_all(\"span\", attrs={\"class\": \"description\"})[j].text\n",
    "                    \n",
    "                    \n",
    "                #industry                \n",
    "                classNum = len(soup.find_all(\"mat-chip\", attrs={\"class\": \"mat-chip\"}))\n",
    "                industry = \"\"\n",
    "                for j in range(0, classNum):\n",
    "                    if(j!=0):\n",
    "                        industry += ', '\n",
    "                    industry += soup.find_all(\"mat-chip\", attrs={\"class\": \"mat-chip\"})[j].text\n",
    "                    \n",
    "\n",
    "            names.append(name)\n",
    "            descriptions.append(description)            \n",
    "            industries.append(industry)\n",
    "\n",
    "            print(\"Page Number: %d\\ni: %d\\nCompany Name: %s\\n\" % (page, i, name))\n",
    "\n",
    "            driver.back()\n",
    "            time.sleep(sleepTime)\n",
    "            driver.find_element_by_xpath(mouse_move).click()\n",
    "            time.sleep(sleepTime)\n",
    "            \n",
    "            \n",
    "        if(stopNum!=51):\n",
    "            print(\"error occured\", stopNum)\n",
    "            break    \n",
    "        print(\"next\")    \n",
    "        driver.find_element_by_xpath(next_button).click()            \n",
    "        time.sleep(6)\n",
    "        page += 1        \n",
    "\n",
    "except:\n",
    "    duration = 1000  # milliseconds\n",
    "    freq = 440  # Hz\n",
    "    winsound.Beep(freq, duration)\n",
    "    \n",
    "    #play mario    \n",
    "    Beep(659, 65)\n",
    "    Beep(659, 125)\n",
    "    time.sleep(0.125)\n",
    "    Beep(659, 125)\n",
    "    time.sleep(0.167)\n",
    "    Beep(523, 65)\n",
    "    Beep(659, 125)\n",
    "    time.sleep(0.125)\n",
    "    Beep(784, 125)\n",
    "    time.sleep(0.625)\n",
    "    Beep(392, 155)\n",
    "    time.sleep(0.375)\n",
    "    \n",
    "    print('error occured')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNum+=1\n",
    "df = pd.DataFrame({\"company\": names, \"description\": descriptions, \"industries\": industries})\n",
    "df.to_csv(\"business_description_%s_%s.csv\" % (datetime.today().strftime(\"%Y%m%d\"),dfNum), index=False,encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 =df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  746,   850,  4927,  4928,  4929,  4930,  4931,  4932,  4933,\n",
       "         4934,  4935,  4936,  4937,  4938,  4939,  4940,  4941,  4942,\n",
       "         4943,  4944,  4945,  4946,  4947,  4948,  4949,  4950,  4951,\n",
       "         4952,  4953,  4954,  4955,  4956,  4957,  4958,  4959,  4960,\n",
       "         4961,  4962,  4963,  4964,  4965,  4966,  4967,  4968,  4969,\n",
       "         4970,  4971,  4972,  4975,  5127,  6403,  6427,  6568,  7578,\n",
       "         7579,  7585,  7768,  9823,  9824, 10694, 11468, 11469, 11470,\n",
       "        11471, 11472, 11473, 11474, 11475, 11476, 11477, 11478, 11479,\n",
       "        11480, 11481, 11482, 11483, 11484, 11485, 11486, 11487, 11488,\n",
       "        11489, 11490, 11491, 11492, 11493, 11494, 11495, 11496, 11497,\n",
       "        11498, 11499, 11500, 11501, 11502, 11503, 11504, 11505, 11506,\n",
       "        11507, 11508, 11509, 11510, 11511, 11512, 11513, 11514, 11515,\n",
       "        11516, 11517, 13724], dtype=int64),)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(df2.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13915, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>description</th>\n",
       "      <th>industries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Square</td>\n",
       "      <td>Square is a merchant services aggregator and m...</td>\n",
       "      <td>Finance, FinTech, Hardware, Mobile, Mobile Pay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Udemy</td>\n",
       "      <td>Udemy is an online learning platform that help...</td>\n",
       "      <td>E-Learning, EdTech, Education, Software, Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aclima</td>\n",
       "      <td>Aclima delivers hyperlocal air quality data an...</td>\n",
       "      <td>Analytics, Enterprise Software, Location Based...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple is a multinational corporation that desi...</td>\n",
       "      <td>Consumer Electronics, Electronics, Hardware, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plaid</td>\n",
       "      <td>Plaid provides companies the tools and access ...</td>\n",
       "      <td>Financial Services, FinTech, Software</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company                                        description  \\\n",
       "0  Square  Square is a merchant services aggregator and m...   \n",
       "1   Udemy  Udemy is an online learning platform that help...   \n",
       "2  Aclima  Aclima delivers hyperlocal air quality data an...   \n",
       "3   Apple  Apple is a multinational corporation that desi...   \n",
       "4   Plaid  Plaid provides companies the tools and access ...   \n",
       "\n",
       "                                          industries  \n",
       "0  Finance, FinTech, Hardware, Mobile, Mobile Pay...  \n",
       "1  E-Learning, EdTech, Education, Software, Training  \n",
       "2  Analytics, Enterprise Software, Location Based...  \n",
       "3  Consumer Electronics, Electronics, Hardware, M...  \n",
       "4              Financial Services, FinTech, Software  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df2.shape)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13804, 3)\n",
      "(array([], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "df2 = df2.drop_duplicates()\n",
    "print(df2.shape)\n",
    "print(np.where(df2.duplicated()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"description_data.csv\", index=False,encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
